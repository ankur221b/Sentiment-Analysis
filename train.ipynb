{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VckDfM1qiJD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Embedding,LSTM,Bidirectional,Dropout,SpatialDropout1D\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.utils import to_categorical\n",
        "from time import time\n",
        "import pickle\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGlrCWcSL8Oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 1000\n",
        "oov_tok = '<oov>'\n",
        "maxlen = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJxaqy_SSTvU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73d15546-83cd-4e59-e750-a6ad8b9314af"
      },
      "source": [
        "data = pd.read_csv('imdb_reviews.csv',encoding='latin-1')\n",
        "print('dataset loaded')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_5BUEKjSUHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.drop(['Unnamed: 0','type','file'],axis=1)\n",
        "data.columns = [\"review\",\"sentiment\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h_Hm2O1SURZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data[data.sentiment != 'unsup']\n",
        "data['sentiment'] = data['sentiment'].map({'pos': 1, 'neg': 0})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCQJJev0SUX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words = max_features, oov_token = oov_tok, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True)\n",
        "tokenizer.fit_on_texts(data['review'])\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(data['review'])\n",
        "num_words = len(tokenizer.word_index) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx-ofVnoSUge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
        "train_y = data['sentiment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_AK7DQzyJUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y = to_categorical(train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jAruoDXzXqo",
        "colab_type": "code",
        "outputId": "8341efae-914e-4958-ef7f-9ae1677f4e89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(num_words,64))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(Bidirectional(LSTM(64,return_sequences=True, dropout=0.2)))\n",
        "model.add(Bidirectional(LSTM(32, dropout=0.2,recurrent_dropout=0.2)))\n",
        "model.add(Dropout(0.05))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 64)          7915712   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, None, 64)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, None, 128)         66048     \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 64)                41216     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 8,023,106\n",
            "Trainable params: 8,023,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRErP1GC6_bh",
        "colab_type": "code",
        "outputId": "2ef81af7-03fd-451a-984f-6fd7a09fede0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_x,train_y,batch_size=5000,epochs=25,verbose=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/25\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "50000/50000 [==============================] - 18s 363us/step - loss: 0.6915 - acc: 0.5418\n",
            "Epoch 2/25\n",
            "50000/50000 [==============================] - 6s 129us/step - loss: 0.6760 - acc: 0.6140\n",
            "Epoch 3/25\n",
            "50000/50000 [==============================] - 6s 129us/step - loss: 0.5784 - acc: 0.7010\n",
            "Epoch 4/25\n",
            "50000/50000 [==============================] - 7s 132us/step - loss: 0.4824 - acc: 0.7701\n",
            "Epoch 5/25\n",
            "50000/50000 [==============================] - 6s 129us/step - loss: 0.4315 - acc: 0.8012\n",
            "Epoch 6/25\n",
            "50000/50000 [==============================] - 6s 129us/step - loss: 0.4001 - acc: 0.8192\n",
            "Epoch 7/25\n",
            "50000/50000 [==============================] - 6s 128us/step - loss: 0.3838 - acc: 0.8292\n",
            "Epoch 8/25\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 0.3749 - acc: 0.8341\n",
            "Epoch 9/25\n",
            "50000/50000 [==============================] - 6s 129us/step - loss: 0.3668 - acc: 0.8367\n",
            "Epoch 10/25\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 0.3630 - acc: 0.8401\n",
            "Epoch 11/25\n",
            "50000/50000 [==============================] - 6s 129us/step - loss: 0.3584 - acc: 0.8418\n",
            "Epoch 12/25\n",
            "50000/50000 [==============================] - 6s 129us/step - loss: 0.3572 - acc: 0.8423\n",
            "Epoch 13/25\n",
            "50000/50000 [==============================] - 7s 130us/step - loss: 0.3527 - acc: 0.8431\n",
            "Epoch 14/25\n",
            "50000/50000 [==============================] - 7s 130us/step - loss: 0.3490 - acc: 0.8456\n",
            "Epoch 15/25\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 0.3453 - acc: 0.8474\n",
            "Epoch 16/25\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 0.3440 - acc: 0.8495\n",
            "Epoch 17/25\n",
            "50000/50000 [==============================] - 7s 130us/step - loss: 0.3420 - acc: 0.8488\n",
            "Epoch 18/25\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 0.3398 - acc: 0.8505\n",
            "Epoch 19/25\n",
            "50000/50000 [==============================] - 7s 132us/step - loss: 0.3380 - acc: 0.8494\n",
            "Epoch 20/25\n",
            "50000/50000 [==============================] - 6s 130us/step - loss: 0.3329 - acc: 0.8523\n",
            "Epoch 21/25\n",
            "50000/50000 [==============================] - 6s 130us/step - loss: 0.3337 - acc: 0.8533\n",
            "Epoch 22/25\n",
            "50000/50000 [==============================] - 7s 130us/step - loss: 0.3330 - acc: 0.8528\n",
            "Epoch 23/25\n",
            "50000/50000 [==============================] - 6s 130us/step - loss: 0.3348 - acc: 0.8523\n",
            "Epoch 24/25\n",
            "50000/50000 [==============================] - 6s 129us/step - loss: 0.3304 - acc: 0.8531\n",
            "Epoch 25/25\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 0.3262 - acc: 0.8560\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa9483c3eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Eyj6c3zkVq-",
        "colab_type": "code",
        "outputId": "6b9340d2-46db-4baf-a13a-e40ec6bf3a5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "s = 'Excellent movie'\n",
        "\n",
        "test = tokenizer.texts_to_sequences([s])\n",
        "\n",
        "test = sequence.pad_sequences(test, maxlen=maxlen)\n",
        "\n",
        "sentiment = model.predict(test)[0]\n",
        "\n",
        "if(np.argmax(sentiment) == 0):\n",
        "    print(\"negative\")\n",
        "elif (np.argmax(sentiment) == 1):\n",
        "    print(\"positive\")\n",
        "sentiment"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.10695802, 0.893042  ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86IqnZ6UmHYw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = open('model.pkl','wb')\n",
        "pickle.dump(model,out)\n",
        "out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lqDBrvIRsEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = open('tokenizer.pkl','wb')\n",
        "pickle.dump(tokenizer,out)\n",
        "out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}